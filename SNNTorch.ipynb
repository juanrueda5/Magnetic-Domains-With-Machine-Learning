{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyNaLG62bX0sxIOsdiW1s02t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juanrueda5/Magnetic-Domains-With-Machine-Learning/blob/main/SNNTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install snntorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyOYIW1p4A4N",
        "outputId": "e4a6fb4f-c1d8-47a9-d98d-6ed6e276f689"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting snntorch\n",
            "  Downloading snntorch-0.9.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/125.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m122.9/125.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.3/125.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from snntorch) (2.2.1+cu121)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from snntorch) (2.0.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from snntorch) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from snntorch) (1.25.2)\n",
            "Collecting nir (from snntorch)\n",
            "  Downloading nir-1.0.4-py3-none-any.whl (18 kB)\n",
            "Collecting nirtorch (from snntorch)\n",
            "  Downloading nirtorch-1.0-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->snntorch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->snntorch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->snntorch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->snntorch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->snntorch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->snntorch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.1.0->snntorch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.1.0->snntorch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.1.0->snntorch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.1.0->snntorch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.1.0->snntorch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.1.0->snntorch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.1.0->snntorch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.1.0->snntorch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.1.0->snntorch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.1.0->snntorch)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.1.0->snntorch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->snntorch) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.1.0->snntorch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (2.8.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from nir->snntorch) (3.9.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->snntorch) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->snntorch) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->snntorch) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.1.0->snntorch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.1.0->snntorch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nir, nvidia-cusolver-cu12, nirtorch, snntorch\n",
            "Successfully installed nir-1.0.4 nirtorch-1.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 snntorch-0.9.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6iSt4313itT",
        "outputId": "623e2f49-7462-452e-9245-df554af17631"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import snntorch as snn\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "IdvAU_q-5ahZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import io\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.transforms import ToTensor\n",
        "import zipfile\n",
        "import PIL"
      ],
      "metadata": {
        "id": "xeFSoo01hBsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.backends.cudnn as cudnn\n",
        "from tqdm import tqdm\n",
        "cudnn.benchmark = True"
      ],
      "metadata": {
        "id": "RMuc-qFEhP1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torchvision import datasets, models, transforms\n",
        "import time\n",
        "import os\n",
        "from tempfile import TemporaryDirectory"
      ],
      "metadata": {
        "id": "eYlmObgchE-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_steps = 100\n",
        "batch_size =128\n",
        "num_epochs = 15\n",
        "\n",
        "dtype = torch.float# Torch Variables"
      ],
      "metadata": {
        "id": "CXvffnyM4WnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Define Device**"
      ],
      "metadata": {
        "id": "S1SpUjL8-Aoo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "Y7bRejON-AFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Transformations**"
      ],
      "metadata": {
        "id": "fsjlZcxcJ8N5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.Resize((256,256)),\n",
        "            transforms.Grayscale(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0,), (1,))\n",
        "            ]),\n",
        "    'val': transforms.Compose([\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.Resize((256,256)),\n",
        "            transforms.Grayscale(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0,), (1,))\n",
        "            ]),\n",
        "}"
      ],
      "metadata": {
        "id": "f4oUikBBJ7lE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Read Images on ZipFiles**"
      ],
      "metadata": {
        "id": "CAf-WgUOptoO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ZipDataset():\n",
        "    def __init__(self, root_path, var,trns, cache_into_memory=False):\n",
        "        if cache_into_memory:\n",
        "            f = open(root_path, 'rb')\n",
        "            self.zip_content = f.read()\n",
        "            f.close()\n",
        "            self.zip_file = zipfile.ZipFile(io.BytesIO(self.zip_content), 'r')\n",
        "        else:\n",
        "            self.zip_file = zipfile.ZipFile(root_path, 'r')\n",
        "        self.name_list = list(filter(lambda x: var in x, self.zip_file.namelist()))\n",
        "        self.to_tensor = ToTensor()\n",
        "        self.transf = trns[var]\n",
        "    def __getitem__(self, key):\n",
        "        buf = self.zip_file.read(name=self.name_list[key])\n",
        "        img = cv2.imdecode(np.frombuffer(buf, dtype=np.uint8), cv2.IMREAD_COLOR)\n",
        "        img = PIL.Image.fromarray(img)\n",
        "        values = self.name_list[key].split('_')\n",
        "        Ms = float(values[0].split('/')[-1])\n",
        "        Aex = float(values[1])\n",
        "        keff = float(values[2])\n",
        "        alpha = float(values[3])\n",
        "        maxMs = 1900000.0\n",
        "        maxAex = 2.4999999999999998e-11\n",
        "        maxkeff = 1000000.0\n",
        "        maxalpha = 0.95\n",
        "        target = [Ms, Aex, keff, alpha]\n",
        "        target = torch.tensor(target, dtype=torch.float32)\n",
        "        img = self.transf(img)\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.name_list)"
      ],
      "metadata": {
        "id": "kGZO6YWx8o4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path1= '/content/drive/MyDrive/FinalDataMD/CroppedImages.zip'\n",
        "ZipDataset(root_path=path1, var='train', trns=data_transforms).__getitem__(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enhOtROsJRRc",
        "outputId": "2492e405-c2b6-4eb6-9e20-250d1b3a27ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[0.0392, 0.0275, 0.0235,  ..., 0.8510, 0.8627, 0.8824],\n",
              "          [0.0353, 0.0235, 0.0235,  ..., 0.8588, 0.8471, 0.8588],\n",
              "          [0.0353, 0.0353, 0.0353,  ..., 0.8745, 0.8471, 0.8471],\n",
              "          ...,\n",
              "          [0.0275, 0.0392, 0.0431,  ..., 0.0275, 0.0235, 0.0235],\n",
              "          [0.0745, 0.0863, 0.0941,  ..., 0.0275, 0.0235, 0.0275],\n",
              "          [0.2392, 0.2471, 0.2706,  ..., 0.0314, 0.0314, 0.0314]]]),\n",
              " tensor([1.9000e+06, 2.5000e-11, 4.0000e+05, 7.5000e-01]))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train = ZipDataset(root_path = path1,var='train', trns = data_transforms, cache_into_memory=False)\n",
        "dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=16, shuffle=True)\n",
        "dataset_val = ZipDataset(path1,var='val',trns = data_transforms,cache_into_memory=False)\n",
        "dataloader_val = torch.utils.data.DataLoader(dataset_val, batch_size=16, shuffle=True)\n",
        "image_datasets = {'train': dataset_train, 'val': dataset_val}\n",
        "dataloaders = {'train': dataloader_train, 'val': dataloader_val}\n",
        "dataset_sizes = {'train': len(image_datasets['train']),'val': len(image_datasets['val'])}\n",
        "print(dataset_sizes)"
      ],
      "metadata": {
        "id": "XiHBugFANGFU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61a6bdeb-d17a-4d05-a945-d7545438fe18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'train': 203, 'val': 53}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Surrogate Function**"
      ],
      "metadata": {
        "id": "MbjTbP_SbSmN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from snntorch import surrogate\n",
        "spike_grad = surrogate.fast_sigmoid(slope=25)\n",
        "beta = 0.5\n",
        "num_steps = 50\n"
      ],
      "metadata": {
        "id": "SVebY3RTb0La"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = nn.Sequential(nn.Conv2d(1, 32, 3),\n",
        "                    nn.MaxPool2d(2),\n",
        "                    snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True),\n",
        "                    nn.Conv2d(32, 64, 3),\n",
        "                    nn.MaxPool2d(2),\n",
        "                    snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True),\n",
        "                    nn.Conv2d(64, 128, 3),\n",
        "                    nn.AdaptiveAvgPool2d((1,1)),\n",
        "                    nn.Flatten(),\n",
        "                    nn.Linear(128, 256),\n",
        "                    snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True),\n",
        "                    nn.Linear(256,128),\n",
        "                    snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True),\n",
        "                    nn.Linear(128,64),\n",
        "                    snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True),\n",
        "                    nn.Linear(64,4),\n",
        "                    snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True, output=True),\n",
        "                    ).to(device)"
      ],
      "metadata": {
        "id": "9EUTxx-zfiAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from snntorch import utils\n",
        "def forward_pass(net, num_steps, data):\n",
        "  mem_rec = []\n",
        "  spk_rec = []\n",
        "  utils.reset(net)\n",
        "  #forward pass\n",
        "  for step in range(num_steps):\n",
        "      spk_out, mem_out = net(data)\n",
        "      spk_rec.append(spk_out)\n",
        "      mem_rec.append(mem_out)\n",
        "  spk_tensor = torch.stack(spk_rec,dim = 0)\n",
        "  mem_tensor = torch.stack(mem_rec, dim = 0)\n",
        "  #compute mean\n",
        "  spk_avg = torch.mean(spk_tensor, dim=0)\n",
        "  mem_avg = torch.mean(mem_tensor, dim=0)\n",
        "\n",
        "  return spk_tensor, mem_tensor\n"
      ],
      "metadata": {
        "id": "M0bNtcvn68sO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def acc_rate(spk_out, targets):\n",
        "   idx = spk_out.sum(dim=0)\n",
        "   accuracy = np.mean((targets == idx).detach().cpu().numpy())\n",
        "   return accuracy"
      ],
      "metadata": {
        "id": "b56SjAARVUyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Batch Accuracy**"
      ],
      "metadata": {
        "id": "ICc1HTwt9rBp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_accuracy(train_loader, net, num_steps):\n",
        "  with torch.no_grad():\n",
        "    total = 0\n",
        "    acc = 0\n",
        "    net.eval()\n",
        "\n",
        "    train_loader = iter(train_loader)\n",
        "    for data, targets in train_loader:\n",
        "      data = data.to(device)\n",
        "      targets = targets.to(device)\n",
        "      spk_rec, _ = forward_pass(net, num_steps, data)\n",
        "      acc += acc_rate(spk_rec, targets) * spk_rec.size(1)\n",
        "      total += spk_rec.size(1)\n",
        "\n",
        "  return acc/total"
      ],
      "metadata": {
        "id": "qS11xwBu9osP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in net.named_parameters():\n",
        "    print(f\"{name} is on {param.device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gwe9tARLH4_",
        "outputId": "45cceaf4-c5fb-40c0-adfe-f5dec4a3333d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.weight is on cuda:0\n",
            "0.bias is on cuda:0\n",
            "3.weight is on cuda:0\n",
            "3.bias is on cuda:0\n",
            "6.weight is on cuda:0\n",
            "6.bias is on cuda:0\n",
            "9.weight is on cuda:0\n",
            "9.bias is on cuda:0\n",
            "11.weight is on cuda:0\n",
            "11.bias is on cuda:0\n",
            "13.weight is on cuda:0\n",
            "13.bias is on cuda:0\n",
            "15.weight is on cuda:0\n",
            "15.bias is on cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train Loop**"
      ],
      "metadata": {
        "id": "jryC0GpZ8YKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import snntorch.functional as SF\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=1e-2, betas=(0.9, 0.999))\n",
        "num_epochs = 1\n",
        "loss_hist = []\n",
        "test_acc_hist = []\n",
        "counter = 0\n",
        "train_loader = dataloaders['train']\n",
        "test_loader = dataloaders['val']\n",
        "net.to(device)\n",
        "# Outer training loop\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    # Training loop\n",
        "    for data, targets in iter(train_loader):\n",
        "        data = data.to(device)\n",
        "        targets = targets.to(device)\n",
        "        # forward pass\n",
        "        net.train()\n",
        "\n",
        "        spk_rec, mem_rec = forward_pass(net, num_steps, data)\n",
        "        print(spk_rec.shape)\n",
        "        spk_avg = torch.mean(spk_rec, dim=0)\n",
        "        mem_avg = torch.mean(mem_rec, dim=0)\n",
        "        # initialize the loss & sum over time\n",
        "        loss_val = loss_fn(spk_avg, targets)\n",
        "\n",
        "        # Gradient calculation + weight update\n",
        "        optimizer.zero_grad()\n",
        "        loss_val.backward(retain_graph = True)\n",
        "        optimizer.step()\n",
        "\n",
        "        # Store loss history for future plotting\n",
        "        loss_hist.append(loss_val.item())\n",
        "\n",
        "        # Test set\n",
        "        if counter % 50 == 0:\n",
        "          with torch.no_grad():\n",
        "            net.eval()\n",
        "\n",
        "            # Test set forward pass\n",
        "            test_acc = batch_accuracy(train_loader, net, num_steps)\n",
        "            print(f\"Iteration {counter}, Test Acc: {test_acc * 100:.2f}%\\n\")\n",
        "            test_acc_hist.append(test_acc.item())\n",
        "\n",
        "        counter += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LJnJCUk6-b4",
        "outputId": "275fec7e-05a9-49e8-aef9-3bd07c46058a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([50, 16, 4])\n",
            "Iteration 0, Test Acc: 0.00%\n",
            "\n",
            "torch.Size([50, 16, 4])\n",
            "torch.Size([50, 16, 4])\n",
            "torch.Size([50, 16, 4])\n",
            "torch.Size([50, 16, 4])\n",
            "torch.Size([50, 16, 4])\n",
            "torch.Size([50, 16, 4])\n",
            "torch.Size([50, 16, 4])\n",
            "torch.Size([50, 16, 4])\n",
            "torch.Size([50, 16, 4])\n",
            "torch.Size([50, 16, 4])\n",
            "torch.Size([50, 16, 4])\n",
            "torch.Size([50, 11, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=1e-2, betas=(0.9, 0.999))\n",
        "num_epochs = 10\n",
        "loss_hist = []\n",
        "test_acc_hist = []\n",
        "counter = 0\n",
        "train_loader = dataloaders['train']\n",
        "test_loader = dataloaders['val']\n",
        "scheduler = lr_scheduler.MultiStepLR(optimizer,\n",
        "                        milestones=[8, 24, 28], # List of epoch indices\n",
        "                        gamma =0.5) # Multiplicative factor of learning rate decay\n",
        "net.to(device)"
      ],
      "metadata": {
        "id": "PqZnlKTbe7M6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=4):\n",
        "    since = time.time()\n",
        "    # Create a temporary directory to save training checkpoints\n",
        "    with TemporaryDirectory() as tempdir:\n",
        "        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
        "\n",
        "        torch.save(model.state_dict(), best_model_params_path)\n",
        "        best_acc = 0.0\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "            print('-' * 10)\n",
        "\n",
        "            # Each epoch has a training and validation phase\n",
        "            for phase in ['train', 'val']:\n",
        "                if phase == 'train':\n",
        "                    model.train()  # Set model to training mode\n",
        "                else:\n",
        "                    model.eval()   # Set model to evaluate mode\n",
        "\n",
        "                running_loss = 0.0\n",
        "                running_corrects = 0\n",
        "\n",
        "                # Iterate over data.\n",
        "                for inputs, labels in tqdm(dataloaders[phase],leave=False):\n",
        "                    try:\n",
        "                      inputs = inputs.to(device)\n",
        "                      labels = labels.to(device)\n",
        "\n",
        "                      # zero the parameter gradients\n",
        "                      optimizer.zero_grad()\n",
        "\n",
        "                      # forward\n",
        "                      # track history if only in train\n",
        "                      with torch.set_grad_enabled(phase == 'train'):\n",
        "                          outputs = model(inputs)\n",
        "                          _, preds = torch.max(outputs, 1)\n",
        "                          loss = criterion(outputs, labels)\n",
        "\n",
        "                          # backward + optimize only if in training phase\n",
        "                          if phase == 'train':\n",
        "                              loss.backward()\n",
        "                              optimizer.step()\n",
        "                    except Exception as e:\n",
        "                      pass\n",
        "                    # statistics\n",
        "                    print(labels.data)\n",
        "                    running_loss += loss.item() * inputs.size(0)\n",
        "                    running_corrects += torch.sum(preds == labels.data)\n",
        "                if phase == 'train':\n",
        "                    scheduler.step()\n",
        "\n",
        "                epoch_loss = running_loss / dataset_sizes[phase]\n",
        "                epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "                # deep copy the model\n",
        "                if phase == 'val' and epoch_acc > best_acc:\n",
        "                    best_acc = epoch_acc\n",
        "                    torch.save(model.state_dict(), best_model_params_path)\n",
        "\n",
        "            print()\n",
        "\n",
        "        time_elapsed = time.time() - since\n",
        "        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "        print(f'Best val Acc: {best_acc:4f}')\n",
        "\n",
        "        # load best model weights\n",
        "\n",
        "        model.load_state_dict(torch.load(best_model_params_path))\n",
        "    return model"
      ],
      "metadata": {
        "id": "ZPaPApgDeqaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "magdom_model = train_model(net,loss_fn,optimizer,scheduler)"
      ],
      "metadata": {
        "id": "tY6FppI7e0nb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from snntorch import spikegen\n",
        "\n",
        "# Iterate through minibatches\n",
        "data = iter(dataloader_train)\n",
        "data_it, targets_it = next(data)\n",
        "\n",
        "# Spiking Data\n",
        "spike_data = spikegen.rate(data_it, num_steps=num_steps)"
      ],
      "metadata": {
        "id": "AnyGRhGccI0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ClCMCh7ddGdh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import snntorch.spikeplot as splt\n",
        "from IPython.display import HTML\n"
      ],
      "metadata": {
        "id": "diFp_5o9cyt5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spike_data_sample = spike_data[:, 0, 0]"
      ],
      "metadata": {
        "id": "zWs5minJcze7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "anim = splt.animator(spike_data_sample, fig, ax)\n",
        "# plt.rcParams['animation.ffmpeg_path'] = 'C:\\\\path\\\\to\\\\your\\\\ffmpeg.exe'\n",
        "\n",
        "HTML(anim.to_html5_video())"
      ],
      "metadata": {
        "id": "XfDGgt_Wc2jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LRtMS0aIc62i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Crop Images**"
      ],
      "metadata": {
        "id": "tJcBlr0XpmoP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 as cv\n",
        "import os\n",
        "\n",
        "#First get the list of images in the folder\n",
        "source = \"/content/drive/MyDrive/SNNTorch/\"\n",
        "list_of_original_images = os.listdir(\"/content/drive/MyDrive/SNNTorch\") #Add the path to the folder\n",
        "#Create a new directory to store the cropped images\n",
        "imgpath = \"/content/drive/MyDrive/CroppedImages/\"\n",
        "\n",
        "#Iterate through the image_list\n",
        "for image_path in list_of_original_images:\n",
        "    image_array = cv.imread(source + image_path) # Here we load image using opencv\n",
        "    image_array = np.asarray(image_array) # Here we convert the image to numpy array\n",
        "    print\n",
        "    print(image_array.shape)\n",
        "    height,width,channel = image_array.shape #Here we get the height,width and color channel\n",
        "    cropped_image = image_array[9:458,60:518] # Using array slicing we cut some part of the image and save in a new variable\n",
        "\n",
        "    # Write cropped image to Cropped Images folder\n",
        "    cv.imwrite(imgpath + image_path, cropped_image)"
      ],
      "metadata": {
        "id": "FVLpUeidgZ92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Change name to better format**"
      ],
      "metadata": {
        "id": "6cRs6hp3_pHA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#First get the list of images in the folder\n",
        "source = \"/content/drive/MyDrive/SNNTorch/\"\n",
        "list_of_original_images = os.listdir(\"/content/drive/MyDrive/SNNTorch\") #Add the path to the folder\n",
        "#Create a new directory to store the cropped images\n",
        "imgpath = \"/content/drive/MyDrive/CroppedImages/\"\n",
        "\n",
        "#Iterate through the image_list\n",
        "for image_path in list_of_original_images:\n",
        "  list_val = image_path.split('-')\n",
        "  Ms = list_val[1]\n",
        "  Aex = list_val[3] + '-11'\n",
        "  keff = list_val[6]\n",
        "  alpha = list_val[8].split('.')\n",
        "  alpha = alpha[0]+'.'+alpha[1]\n",
        "  name = Ms + '_' + Aex + '_' + keff + '_' + alpha + '_' + '.png'\n",
        "  os.rename(imgpath + image_path, imgpath + name)"
      ],
      "metadata": {
        "id": "NhtKV1nkklCB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "db74b6e7-fc6c-4ee9-804e-c48da2b9d684"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/CroppedImages/Ms-1000000.0-Aex-1.5e-11-keff-100000.0-alpha-0.95.png' -> '/content/drive/MyDrive/CroppedImages/1000000.0_1.5e-11_100000.0_0.95_.png'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-00a658b904f9>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mAex\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mkeff\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.png'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m   \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/CroppedImages/Ms-1000000.0-Aex-1.5e-11-keff-100000.0-alpha-0.95.png' -> '/content/drive/MyDrive/CroppedImages/1000000.0_1.5e-11_100000.0_0.95_.png'"
          ]
        }
      ]
    }
  ]
}